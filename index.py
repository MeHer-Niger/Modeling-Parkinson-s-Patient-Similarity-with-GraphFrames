# -*- coding: utf-8 -*-
"""Exercise 4 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/146x3HdQZVN6ghmz8yy5ROYU8J10bJmwC
"""

# Spark & GraphFrames Setup
import os
from pyspark.sql import SparkSession

os.environ["PYSPARK_SUBMIT_ARGS"] = "--packages graphframes:graphframes:0.8.4-spark3.5-s_2.12 pyspark-shell"

spark = SparkSession.builder \
    .appName("StudentGraph") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
from graphframes import GraphFrame

# Setup
import os
from pyspark.sql import SparkSession
os.environ["PYSPARK_SUBMIT_ARGS"] = "--packages graphframes:graphframes:0.8.4-spark3.5-s_2.12 pyspark-shell"

spark = SparkSession.builder.appName("ParkinsonGraph").getOrCreate()

import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
from graphframes import GraphFrame

# Load the dataset
df = pd.read_csv("parkinsons_telemonitoring.csv")

# Group by subject to get average motor_UPDRS (we'll use this for similarity)
avg_updrs = df.groupby("subject#")["motor_UPDRS"].mean().reset_index()
avg_updrs.columns = ["id", "avg_motor_UPDRS"]

# Create vertices: each subject is a node
vertices = spark.createDataFrame(avg_updrs)

# Create edges: connect subjects whose motor_UPDRS differs by less than 2
pairs = avg_updrs.merge(avg_updrs, how="cross")
pairs = pairs[pairs["id_x"] != pairs["id_y"]]
pairs["diff"] = abs(pairs["avg_motor_UPDRS_x"] - pairs["avg_motor_UPDRS_y"])
similar_pairs = pairs[pairs["diff"] < 2.0][["id_x", "id_y"]].drop_duplicates()
similar_pairs.columns = ["src", "dst"]
edges = spark.createDataFrame(similar_pairs)

# Build the graph
graph = GraphFrame(vertices, edges)

# Step 1: Run PageRank
pagerank = graph.pageRank(resetProbability=0.15, maxIter=5)

# Step 2: Get subject metadata (e.g., sex, age)
subject_info = df[["subject#", "age", "sex"]].drop_duplicates()
subject_info.columns = ["id", "age", "sex"]

# Convert to Spark DataFrame
subject_info_spark = spark.createDataFrame(subject_info)

# Step 3: Join PageRank result with subject metadata
ranked = pagerank.vertices.join(subject_info_spark, on="id", how="left")

# Step 4: Show top-ranked subjects
ranked.select("id", "age", "sex", "pagerank").orderBy("pagerank", ascending=False).show(truncate=False)

# âœ… Step 1: Show a few valid subject IDs from your graph
valid_ids = [row['id'] for row in graph.vertices.limit(10).collect()]
print("Valid subject IDs:", valid_ids)

# âœ… Step 2: Choose two subjects as landmarks
sample_ids = valid_ids[:2]  # Use first 2 valid subjects

# âœ… Step 3: Compute shortest paths from selected subjects
shortest_paths = graph.shortestPaths(landmarks=sample_ids)

# âœ… Step 4: Show result
shortest_paths.select("id", "distances").show(truncate=False)

# âœ… Step 1: Run connectedComponents()
spark.sparkContext.setCheckpointDir("/tmp/graphframes-checkpoint")
components = graph.connectedComponents()

# âœ… Step 2: Prepare subject metadata (age and sex)
subject_info = df[["subject#", "age", "sex"]].drop_duplicates()
subject_info.columns = ["id", "age", "sex"]  # match GraphFrame column

subject_info_spark = spark.createDataFrame(subject_info)

# âœ… Step 3: Join component results with subject info
joined_components = components.join(subject_info_spark, on="id", how="left")

# âœ… Step 4: Display the component memberships
joined_components.select("id", "age", "sex", "component").orderBy("component").show(truncate=False)

# Step 5: Triangle motif detection on undirected edges
flipped_edges = edges.selectExpr("dst as src", "src as dst")
bidirectional_edges = edges.union(flipped_edges).dropDuplicates()
undirected_graph = GraphFrame(vertices, bidirectional_edges)
motifs = undirected_graph.find("(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(a)")

print("Triangle Motifs Found:")
motifs.show(truncate=False)

# âœ… Step 1: Compute in-degree (how many edges point to each subject)
in_degrees = graph.inDegrees.orderBy("inDegree", ascending=False)

# âœ… Step 2: Compute out-degree (how many edges go out from each subject)
out_degrees = graph.outDegrees.orderBy("outDegree", ascending=False)

# âœ… Step 3: Show results
print("ðŸ”½ Subjects with highest in-degree:")
in_degrees.show()

print("ðŸ”¼ Subjects with highest out-degree:")
out_degrees.show()

# Step 6: Visualization using NetworkX
pagerank_pd = pagerank.vertices.select("id", "pagerank").toPandas()
vertices_pd = vertices.toPandas()
edges_pd = bidirectional_edges.toPandas()

viz_df = pd.merge(vertices_pd, pagerank_pd, on="id")
viz_df["normPR"] = (viz_df["pagerank"] - viz_df["pagerank"].min()) / (viz_df["pagerank"].max() - viz_df["pagerank"].min())

# Create NetworkX graph
G = nx.Graph()
for _, row in viz_df.iterrows():
    G.add_node(row["id"], pagerank=row["pagerank"], normPR=row["normPR"])
for _, row in edges_pd.iterrows():
    G.add_edge(row["src"], row["dst"])

pos = nx.spring_layout(G, seed=42)
colors = [plt.cm.Blues(G.nodes[n]["normPR"]) for n in G.nodes]

plt.figure(figsize=(12, 10))
nx.draw(G, pos, node_color=colors, with_labels=True, node_size=600, edge_color="gray")
plt.title("Parkinson's Subject Similarity Graph (by motor_UPDRS)", fontsize=14)
plt.axis("off")
plt.show()

# Sample simulation of a simplified Parkinson patient similarity graph for visualization
# Since we don't have the actual dataset, simulate small example for visualization

# Simulated patients and edges based on similar UPDRS scores
patients = [("P1", 1.2), ("P2", 2.1), ("P3", 3.0), ("P4", 2.9), ("P5", 1.0)]
edges = [("P1", "P2"), ("P2", "P3"), ("P3", "P4"), ("P1", "P5"), ("P2", "P4")]

# Create graph
G2 = nx.Graph()
G2.add_edges_from(edges)

# Generate layout and draw
plt.figure(figsize=(10, 6))
pos = nx.spring_layout(G2, seed=42)

nx.draw_networkx_nodes(G2, pos, node_size=800, node_color="lightgreen")
nx.draw_networkx_edges(G2, pos, width=2, edge_color="gray")
nx.draw_networkx_labels(G2, pos, font_size=10, font_weight='bold')

plt.title("Parkinsonâ€™s Patient Similarity Network", fontsize=14)
plt.axis("off")
plt.tight_layout()
plt.show()